{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Part 2:\n",
    "## Using movie name to get recommendation result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* to run this file successfully, you need the following code:\n",
    "* !pip install gensim\n",
    "* !pip install nltk\n",
    "* !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the package used for this file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation job 1: Text Mining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access database and store it in a dataframe\n",
    "a = pd.read_csv('project_data',index_col = 'Unnamed: 0')\n",
    "a.set_index('index',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datafame to nested dictionary\n",
    "def dataframe_to_dict(df):\n",
    "    dict_ = dict()\n",
    "    for i in df.index:\n",
    "        dict_[i] = dict()\n",
    "        if pd.notnull(df['director'][i]):\n",
    "            dict_[i]['director'] = [i.strip(\"''\") for i in df['director'][i][1:-1].split(', ')]\n",
    "        else:\n",
    "            dict_[i]['director'] = 'NaN'\n",
    "        if pd.notnull(df['genres'][i]):\n",
    "            dict_[i]['genres'] = [i.strip(\"''\") for i in df['genres'][i][1:-1].split(', ')]\n",
    "        else:\n",
    "            dict_[i]['genres'] = 'NaN'\n",
    "        if pd.notnull(df['keywords'][i]):\n",
    "            dict_[i]['keywords'] = [i.strip(\"''\") for i in df['keywords'][i][1:-1].split(', ')]\n",
    "        else:\n",
    "            dict_[i]['keywords'] = 'NaN'\n",
    "        if pd.notnull(df['rating_value'][i]):\n",
    "            dict_[i]['rating_value'] = float(df['rating_value'][i])\n",
    "        else:\n",
    "            dict_[i]['rating_value'] = 0\n",
    "        if pd.notnull(df['release_country'][i]):\n",
    "            dict_[i]['release_country'] = [i.strip(\"''\") for i in df['release_country'][i][1:-1].split(', ')]\n",
    "        else:\n",
    "            dict_[i]['release_country'] = 'NaN'\n",
    "        if pd.notnull(df['release_date'][i]):\n",
    "            dict_[i]['release_date'] = df['release_date'][i]\n",
    "        else:\n",
    "            dict_[i]['release_date'] = 'NaN'\n",
    "        if pd.notnull(df['reviews'][i]) and df['reviews'][i] != []:\n",
    "            dict_[i]['reviews'] = df['reviews'][i].replace('\"',\"\\'\").strip(\"['\").strip(\"']\").split(\"', '\")\n",
    "            dict_[i]['reviews_number'] = len(dict_[i]['reviews'])\n",
    "        else:\n",
    "            dict_[i]['reviews'] = 'NaN'\n",
    "            dict_[i]['reviews_number'] = 0\n",
    "        if pd.notnull(df['stars'][i]):\n",
    "            dict_[i]['stars'] = [i.strip(\"''\") for i in df['stars'][i][1:-1].split(', ')]\n",
    "        else:\n",
    "            dict_[i]['stars'] = 'NaN'\n",
    "        if pd.notnull(df['storyline'][i]):\n",
    "            dict_[i]['storyline'] = df['storyline'][i]\n",
    "        else:\n",
    "            dict_[i]['storyline'] = 'NaN'\n",
    "        if pd.notnull(df['time'][i]):\n",
    "            dict_[i]['time'] = df['time'][i]\n",
    "        else:\n",
    "            dict_[i]['time'] = 'NaN'\n",
    "        if pd.notnull(df['writers'][i]):\n",
    "            dict_[i]['writers'] = [i.strip(\"''\") for i in df['writers'][i][1:-1].split(', ')]\n",
    "        else:\n",
    "            dict_[i]['writers'] = 'NaN'\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store keywords, genres, storyline, and reviews of each movie into a list as our reference doc\n",
    "new_dict = dataframe_to_dict(a)\n",
    "doc_list = list()\n",
    "for key in new_dict.keys(): \n",
    "    if new_dict[key]['keywords'] == 'NaN':\n",
    "        doc_list.append((new_dict[key]['storyline']+ ' '+' '.join(new_dict[key]['genres'])+' '+' '.join(new_dict[key]['reviews'])).replace('NaN',''))\n",
    "    else:\n",
    "        doc_list.append((' '.join(new_dict[key]['keywords'])+ ' '+new_dict[key]['storyline']+ ' '+' '.join(new_dict[key]['genres'])+' '+' '.join(new_dict[key]['reviews'])).replace('NaN',''))\n",
    "\n",
    "for i in range(len(doc_list)):\n",
    "    string = doc_list[i]\n",
    "    string = string.replace('\"','')\n",
    "    doc_list[i] = string  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation job 2: Similarity\n",
    "#### Given a corpus of movie documents, when a new movie arrives, find the documents that are similar to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct LSI model with reference doc\n",
    "for i in range(len(doc_list)):\n",
    "    story = doc_list[i]\n",
    "    sents = sent_tokenize(story)\n",
    "    for j in range(len(sents)):\n",
    "        sent = sents[j]\n",
    "        sent = sent.strip().replace('\\n','')\n",
    "        sents[j] = sent\n",
    "    doc_list[i] = '. '.join(sents)\n",
    "texts = [[word for word in story.lower().split()\n",
    "        if word not in STOPWORDS and word.isalnum()]\n",
    "        for story in doc_list]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similarities of movies based on movie content given the user input - a movie name \n",
    "def get_similar_movies(movie_name):\n",
    "    input_doc = doc_list[a.index.get_loc(movie_name)]\n",
    "    vec_bow = dictionary.doc2bow(input_doc.lower().split())\n",
    "    vec_lsi = lsi[vec_bow]\n",
    "    index = similarities.MatrixSimilarity(lsi[corpus])\n",
    "    sims = index[vec_lsi]\n",
    "    sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with only numerical values \n",
    "df_grade = pd.read_csv('grade',index_col = 'Unnamed: 0')\n",
    "\n",
    "# get dataframe with both categorical and numerical values and nomarlize it\n",
    "a2 = pd.read_csv('project_data',index_col = 'Unnamed: 0')\n",
    "a2.set_index('index',inplace = True)\n",
    "a2['director1'] = df_grade['director']/10\n",
    "a2['release_country1'] = df_grade['release_country']/10\n",
    "a2['stars1'] =  df_grade['stars']/10\n",
    "a2['writers1'] = df_grade['writers']/10\n",
    "a2['key_story_genre_review'] = np.zeros((10,1))\n",
    "a2['rating1'] = np.where(a2['rating_value'].isnull(),0,a2['rating_value'])/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation core job:\n",
    "### Using movie name to get recommendation result\n",
    "* movie score is between 0 - 1\n",
    "* scoring rule: heavy weight on content similarities(85%) + minor weight on rating value(5%) + other attributes(total 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score movies between 0 - 1 based on our scoring rule\n",
    "def get_scores(movie_name):\n",
    "    sims= get_similar_movies(movie_name)\n",
    "    for i in sims:\n",
    "        a2['key_story_genre_review'].iloc[i[0]] = i[1]/2 + 1/2\n",
    "    \n",
    "    a2['total_score'] = (a2.director1+ a2.stars1 + a2.writers1)*0.025 + (a2.release_country1)*0.025+a2.key_story_genre_review * 0.85 + a2.rating1 * 0.05\n",
    "    return a2.sort_values(by='total_score', ascending=False)[['director','genres','keywords','rating_value','release_country','release_date','reviews','stars','storyline','time','writers','total_score']].iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get users inputs - a movie name\n",
    "your_movie = input('Please enter the relevant movie name you want to search: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(your_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple analysis: Word Clouds\n",
    "* using function in this part, you can enter any movie name and obtain the idea of genreral content of it by word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw out the wordcloud of a given movie \n",
    "def get_wordcloud(movie_name):\n",
    "    text = doc_list[a.index.get_loc(movie_name)]\n",
    "    # Remove unwanted words\n",
    "    DELETE_WORDS = ['movie','film']\n",
    "    for word in DELETE_WORDS:\n",
    "            text = text.replace(word,' ')\n",
    "    # Remove words with length less than 4\n",
    "    word_list = text.strip().split()\n",
    "    for word in word_list:\n",
    "        if len(word) <= 3:\n",
    "            text = text.replace(' '+word+' ',' ')\n",
    "\n",
    "\n",
    "    wordcloud = WordCloud(stopwords=STOPWORDS,background_color='white',width=4000,height=4000).generate(text)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wordcloud('Tentacles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
