{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Attribute in Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('data',index_col = 'Unnamed: 0')\n",
    "a.set_index('index',inplace = True)\n",
    "a['rating_value_binary'] = np.where(a['rating_value'] >= 7,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get value for each movie's feature\n",
    "b = pd.read_csv('grade',index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the compound value for each movie's review\n",
    "df_SA = pd.read_csv('sentiment_analysis_result',index_col = 'Unnamed: 0')\n",
    "a['compound'] = df_SA['compound']\n",
    "# Normalize the compound value\n",
    "a['compound_grade'] = a['compound']/2+1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b['compound'] = a['compound_grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = a[a['rating_value'].notnull()][['rating_value_binary']]\n",
    "y = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# put movies with rating value into x_and_y\n",
    "x_and_y = y_data.join(b)\n",
    "x_and_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# put movies without rating value into x_not_y\n",
    "x_not_y = a[a['rating_value'].isnull()][['rating_value_binary']].join(b)\n",
    "x_not_y = x_not_y.drop(columns = ['rating_value_binary'])\n",
    "x_not_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build train and test samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(x_and_y, test_size = 0.3)\n",
    "x_train = train.iloc[0:,1:]\n",
    "y_train = train['rating_value_binary']\n",
    "x_test = test.iloc[0:,1:]\n",
    "y_test = test['rating_value_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw cool-warm map \n",
    "import matplotlib.pyplot as plot\n",
    "plot.pcolor(x_not_y.corr(),cmap='coolwarm')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "logistic_acc = model.score(x_test,actuals)\n",
    "print(logistic_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prediction for movies without rating value\n",
    "prediction = x_not_y[['compound']]\n",
    "lr_predictions = model.predict(x_not_y)\n",
    "prediction['lr_predictions'] = lr_predictions\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best combination for parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "parameters = {\n",
    "     'n_estimators':(10, 30, 50, 100), #the number of trees\n",
    "     'max_depth':(4,5,6,8,10,15),\n",
    "     'min_samples_split': (2, 4, 8),\n",
    "     'min_samples_leaf': (4,8,12,16)\n",
    "}\n",
    "\n",
    "model = GridSearchCV(RandomForestClassifier(),parameters,cv=3,iid=False)\n",
    "model.fit(x_train, np.ravel(y_train))\n",
    "model.best_score_, model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the accuracy for the combination\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=15,min_samples_leaf=4,min_samples_split=4,n_estimators=100)\n",
    "rf.fit(x_train,np.ravel(y_train))\n",
    "rf_acc = rf.score(x_test,y_test)\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prediction for movies without rating value\n",
    "rf_predictions = rf.predict(x_not_y)\n",
    "prediction['rf_predictions'] = rf_predictions\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw feature importance image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "feature_names = [key for key in x_not_y]\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='y', align='center')\n",
    "plt.yticks(range(len(indices)),feature_names)\n",
    "plt.xlabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'learning_rate':[\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    'solver': ('sgd','lbfgs','adam'),\n",
    "    'activation': ('logistic','tanh','relu'),\n",
    "    'hidden_layer_sizes': ((30,),(60,),(80,)),\n",
    "    'max_iter': (1500,)\n",
    "}\n",
    "gs = GridSearchCV(estimator = MLPClassifier(), param_grid=parameters,cv=5)\n",
    "gs.fit(x_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the accuracy for the combination\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(60,), max_iter = 1000, \n",
    "                    activation='tanh',\n",
    "                    learning_rate='adaptive')\n",
    "clf.fit(x_train,y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "actuals = np.array(y_test)\n",
    "tp=tn=fp=fn=0\n",
    "for i in range(len(actuals)):\n",
    "    a_class=p_class=0\n",
    "    if int(actuals[i] == 0):\n",
    "        a_class = 1 \n",
    "    if int(predictions[i] == 0):\n",
    "        p_class = 1\n",
    "    if a_class == 1 and p_class == 1:\n",
    "        tp +=1\n",
    "    elif a_class == 1 and p_class == 0:\n",
    "        fn +=1\n",
    "    elif a_class == 0 and p_class == 0:\n",
    "        tn +=1\n",
    "    elif a_class == 0 and p_class == 1:\n",
    "        fp +=1\n",
    "print(tp,tn,fp,fn)\n",
    "nn_accuracy = ((tp+tn)*100/(tp+tn+fp+fn))\n",
    "print(nn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prediction for movies without rating value\n",
    "nn_predictions = clf.predict(x_not_y)\n",
    "prediction['nn_predictions'] = nn_predictions\n",
    "prediction = prediction.drop(columns = 'compound')\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the result into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('prediction1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the prediction result fill None value in raing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.read_csv('prediction1')\n",
    "origin_data = pd.read_csv('data',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set estimated scores greater than 7 to exactly 7.5, others to 4.5\n",
    "prediction_data['pretend_rating_value'] = np.where(prediction_data.apply(lambda x: x['nn_predictions']==1, axis=1),7.5,4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_rating_value = prediction_data[['index','pretend_rating_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the predict rating value into original dataframe\n",
    "update_data = pd.merge(origin_data,update_rating_value,on='index',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use predict rating value fill none value in orginal rating value\n",
    "update_data['rating_value'].fillna(update_data['pretend_rating_value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column ana write data to a new .csv file\n",
    "update_data.drop(columns='pretend_rating_value',inplace=True)\n",
    "update_data.to_csv('update_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
